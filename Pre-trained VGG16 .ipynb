{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.datasets import mnist,fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n"
      ],
      "metadata": {
        "id": "2qSzuQ8lEb0z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer=layers.Input(shape=(48,48,3))\n",
        "model_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n"
      ],
      "metadata": {
        "id": "A4oQ6RiiaN_O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "last_layer=model_vgg16.output\n",
        "flatten=layers.Flatten()(last_layer)\n",
        "\n",
        "# Add dense layer\n",
        "dense1=layers.Dense(100,activation='relu')(flatten)\n",
        "dense1=layers.Dense(100,activation='relu')(flatten)\n",
        "# Add dense layer to the final output layer\n",
        "output_layer=layers.Dense(10,activation='softmax')(flatten)\n",
        "\n",
        "# Creating modle with input and output layer\n",
        "model_m=models.Model(inputs=input_layer,outputs=output_layer)\n"
      ],
      "metadata": {
        "id": "4ldsLehTaN7p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for layer in model_m.layers[:-1]:\n",
        "    layer.trainable=False\n"
      ],
      "metadata": {
        "id": "oyBLAhZ2aN5i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling Model\n",
        "\n",
        "model_m.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vxLlWg1_ah_Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(x_train_m, y_train_m), (x_test_m, y_test_m) = mnist.load_data()\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "\n",
        "x_train_m= np.expand_dims(x_train_m, axis=-1)  # Add channel dimension\n",
        "x_test_m= np.expand_dims(x_test_m, axis=-1)\n",
        "x_train_m = np.repeat(x_train_m, 3, axis=-1)  # Convert to 3 Channels\n",
        "x_test_m= np.repeat(x_test_m, 3, axis=-1)\n",
        "x_train_m = tf.image.resize(x_train_m, (48, 48))  # Resize images to (48, 48)\n",
        "x_test_m = tf.image.resize(x_test_m, (48, 48))\n",
        "x_train_m.shape, x_test_m.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ssrdn5n1wd7",
        "outputId": "b18c049e-b203-4500-ce27-29099237ef11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([60000, 48, 48, 3]), TensorShape([10000, 48, 48, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train_m= x_train_m / 255.0\n",
        "x_test_m = x_test_m / 255.0\n",
        "\n",
        "# Convert labels to categorical format\n",
        "y_train_m= to_categorical(y_train_m, 10)\n",
        "y_test_m = to_categorical(y_test_m, 10)"
      ],
      "metadata": {
        "id": "yJ9siNAH10cA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_m = model_m.fit(x_train_m,y_train_m,epochs=2,batch_size=200,verbose=True,validation_data=(x_test_m,y_test_m))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7Bj0hSgaN0z",
        "outputId": "dc43877a-637f-4011-cb54-9bb0fc3ea397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "282/469 [=================>............] - ETA: 12:39 - loss: 1.2214 - accuracy: 0.7374"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on MNIST testing samples\n",
        "y_pred_m = model_m.predict(x_test_m)\n",
        "y_pred_classes_m = np.argmax(y_pred_m, axis=1)\n",
        "y_true_m = np.argmax(y_test_m, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Compute confusion matrix, precision, recall, and F1 score\n",
        "confusion_m = confusion_matrix(y_true_m, y_pred_classes_m)\n",
        "precision_m = precision_score(y_true_m, y_pred_classes_m, average='weighted')\n",
        "recall_m = recall_score(y_true_m, y_pred_classes_m, average='weighted')\n",
        "f1_m = f1_score(y_true_m, y_pred_classes_m, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix (MNIST):\")\n",
        "print(confusion_m)\n",
        "print(f\"Precision (MNIST): {precision_m}\")\n",
        "print(f\"Recall (MNIST): {recall_m}\")\n",
        "print(f\"F1 Score (MNIST): {f1_m}\")"
      ],
      "metadata": {
        "id": "GUL26MRQaNxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating modle with input and output layer\n",
        "model_f=models.Model(inputs=input_layer,outputs=output_layer)\n",
        "\n",
        "for layer in model_f.layers[:-1]:\n",
        "    layer.trainable=False\n",
        "\n",
        "# Compiling Model\n",
        "\n",
        "model_f.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7rhkjaYFanp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion MNIST dataset\n",
        "(x_train_f, y_train_f), (x_test_f, y_test_f) = fashion_mnist.load_data()\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "\n",
        "x_train_f= np.expand_dims(x_train_f, axis=-1)  # Add channel dimension\n",
        "x_test_f= np.expand_dims(x_test_f, axis=-1)\n",
        "x_train_f = np.repeat(x_train_f, 3, axis=-1)  # Convert to 3 channels image\n",
        "x_test_f = np.repeat(x_test_f, 3, axis=-1)\n",
        "x_train_f = tf.image.resize(x_train_f, (48, 48))  # Resize images to (48, 48)\n",
        "x_test_f = tf.image.resize(x_test_f, (48, 48))\n",
        "x_train_f.shape, x_test_f.shape"
      ],
      "metadata": {
        "id": "mGHWdCH7anmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train_f= x_train_f / 255.0\n",
        "x_test_f = x_test_f / 255.0\n",
        "\n",
        "# Convert labels to categorical format\n",
        "y_train_f= to_categorical(y_train_f, 10)\n",
        "y_test_f= to_categorical(y_test_f, 10)"
      ],
      "metadata": {
        "id": "H9s-pABoankb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_f = model_f.fit(x_train_f,y_train_f,epochs=2,batch_size=200,verbose=True,validation_data=(x_test_f,y_test_f))"
      ],
      "metadata": {
        "id": "FrS35Isx2Ar1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on Fashion MNIST testing samples\n",
        "y_pred_f = model_f.predict(x_test_f)\n",
        "y_pred_classes_f= np.argmax(y_pred_f, axis=1)\n",
        "y_true_f = np.argmax(y_test_f, axis=1)\n",
        "\n",
        "\n",
        "# Compute confusion matrix, precision, recall, and F1 score\n",
        "confusion_f= confusion_matrix(y_true_f, y_pred_classes_f)\n",
        "precision_f = precision_score(y_true_f y_pred_classes_f, average='weighted')\n",
        "recall_f = recall_score(y_true_f, y_pred_classes_f, average='weighted')\n",
        "f1_f = f1_score(y_true_f, y_pred_classes_f, average='weighted')\n",
        "\n",
        "print(\"(Fashion MNIST):\")\n",
        "print(\"Confusion Matrix :\")\n",
        "print(confusion_f)\n",
        "print(f\"Precision : {precision_f}\")\n",
        "print(f\"Recall : {recall_f}\")\n",
        "print(f\"F1 Score : {f1_f}\")"
      ],
      "metadata": {
        "id": "HKGZbTe92Aog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_7CqC6z2Alv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "od4esrMFanhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}